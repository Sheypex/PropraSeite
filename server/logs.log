2019-06-25 22:11:34,312 no email passed on arguments... exception ignored
2019-06-25 22:11:34,330 search type: 1
2019-06-25 22:11:34,335 couldnt get the tweets data... some error ocurred:
Traceback (most recent call last):
  File "./main.py", line 89, in define_action
    return get_tweets()
  File "./main.py", line 54, in get_tweets
    return get_data()
  File "./main.py", line 42, in get_data
    term_result = term_loader.load_term_file(path + search + ".csv").to_json()  # result = JSON_Object containing pair of JSON_Objects
  File "C:\Users\Alex\WebstormProjects\PropraSeite\server\DataAnalisis\term_loader.py", line 52, in load_term_file
    tweets = pd.read_csv(path, sep=";", error_bad_lines=False)
  File "C:\Program Files (x86)\Python37-32\lib\site-packages\pandas\io\parsers.py", line 702, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "C:\Program Files (x86)\Python37-32\lib\site-packages\pandas\io\parsers.py", line 429, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "C:\Program Files (x86)\Python37-32\lib\site-packages\pandas\io\parsers.py", line 895, in __init__
    self._make_engine(self.engine)
  File "C:\Program Files (x86)\Python37-32\lib\site-packages\pandas\io\parsers.py", line 1122, in _make_engine
    self._engine = CParserWrapper(self.f, **self.options)
  File "C:\Program Files (x86)\Python37-32\lib\site-packages\pandas\io\parsers.py", line 1853, in __init__
    self._reader = parsers.TextReader(src, **kwds)
  File "pandas\_libs\parsers.pyx", line 387, in pandas._libs.parsers.TextReader.__cinit__
  File "pandas\_libs\parsers.pyx", line 705, in pandas._libs.parsers.TextReader._setup_parser_source
FileNotFoundError: [Errno 2] File b'/Data/Trump.csv' does not exist: b'/Data/Trump.csv'
2019-06-25 22:13:26,669 no email passed on arguments... exception ignored
2019-06-25 22:13:26,675 search type: 1
2019-06-25 22:13:26,989 couldnt get the tweets data... some error ocurred:
Traceback (most recent call last):
  File "C:/Users/Alex/WebstormProjects/PropraSeite/server/main.py", line 89, in define_action
    return get_tweets()
  File "C:/Users/Alex/WebstormProjects/PropraSeite/server/main.py", line 54, in get_tweets
    return get_data()
  File "C:/Users/Alex/WebstormProjects/PropraSeite/server/main.py", line 45, in get_data
    term_sentiment_result = term_sentiment_analysis_loader.load_terms_sentiment_file(path + search + "Sentiments.csv")
  File "C:\Users\Alex\WebstormProjects\PropraSeite\server\DataAnalisis\term_sentiment_analysis_loader.py", line 6, in load_terms_sentiment_file
    result = pd.read_csv(path, sep=";", error_bad_lines=False)
  File "C:\Users\Alex\WebstormProjects\PropraSeite\venv\lib\site-packages\pandas\io\parsers.py", line 702, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "C:\Users\Alex\WebstormProjects\PropraSeite\venv\lib\site-packages\pandas\io\parsers.py", line 429, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "C:\Users\Alex\WebstormProjects\PropraSeite\venv\lib\site-packages\pandas\io\parsers.py", line 895, in __init__
    self._make_engine(self.engine)
  File "C:\Users\Alex\WebstormProjects\PropraSeite\venv\lib\site-packages\pandas\io\parsers.py", line 1122, in _make_engine
    self._engine = CParserWrapper(self.f, **self.options)
  File "C:\Users\Alex\WebstormProjects\PropraSeite\venv\lib\site-packages\pandas\io\parsers.py", line 1853, in __init__
    self._reader = parsers.TextReader(src, **kwds)
  File "pandas\_libs\parsers.pyx", line 387, in pandas._libs.parsers.TextReader.__cinit__
  File "pandas\_libs\parsers.pyx", line 705, in pandas._libs.parsers.TextReader._setup_parser_source
FileNotFoundError: [Errno 2] File b'Data/KlimawandelSentiments.csv' does not exist: b'Data/KlimawandelSentiments.csv'
2019-06-25 22:14:10,569 no email passed on arguments... exception ignored
2019-06-25 22:14:10,578 search type: 1
2019-06-25 22:14:10,746 couldnt get the tweets data... some error ocurred:
Traceback (most recent call last):
  File "C:/Users/Alex/WebstormProjects/PropraSeite/server/main.py", line 89, in define_action
    return get_tweets()
  File "C:/Users/Alex/WebstormProjects/PropraSeite/server/main.py", line 54, in get_tweets
    return get_data()
  File "C:/Users/Alex/WebstormProjects/PropraSeite/server/main.py", line 45, in get_data
    term_sentiment_result = term_sentiment_analysis_loader.load_terms_sentiment_file(path + search + "Sentiments.csv")
  File "C:\Users\Alex\WebstormProjects\PropraSeite\server\DataAnalisis\term_sentiment_analysis_loader.py", line 6, in load_terms_sentiment_file
    result = pd.read_csv(path, sep=";", error_bad_lines=False)
  File "C:\Users\Alex\WebstormProjects\PropraSeite\venv\lib\site-packages\pandas\io\parsers.py", line 702, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "C:\Users\Alex\WebstormProjects\PropraSeite\venv\lib\site-packages\pandas\io\parsers.py", line 429, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "C:\Users\Alex\WebstormProjects\PropraSeite\venv\lib\site-packages\pandas\io\parsers.py", line 895, in __init__
    self._make_engine(self.engine)
  File "C:\Users\Alex\WebstormProjects\PropraSeite\venv\lib\site-packages\pandas\io\parsers.py", line 1122, in _make_engine
    self._engine = CParserWrapper(self.f, **self.options)
  File "C:\Users\Alex\WebstormProjects\PropraSeite\venv\lib\site-packages\pandas\io\parsers.py", line 1853, in __init__
    self._reader = parsers.TextReader(src, **kwds)
  File "pandas\_libs\parsers.pyx", line 387, in pandas._libs.parsers.TextReader.__cinit__
  File "pandas\_libs\parsers.pyx", line 705, in pandas._libs.parsers.TextReader._setup_parser_source
FileNotFoundError: [Errno 2] File b'Data/KlimawandelSentiments.csv' does not exist: b'Data/KlimawandelSentiments.csv'
2019-06-25 22:14:51,509 no email passed on arguments... exception ignored
2019-06-25 22:14:51,516 search type: 1
2019-06-25 22:14:51,767 result: {"result":{"term":{"1558213200000":16896,"1558216800000":1,"1558220400000":0,"1558224000000":0,"1558227600000":1,"1558231200000":0,"1558234800000":0,"1558238400000":0,"1558242000000":0,"1558245600000":0,"1558249200000":0,"1558252800000":0,"1558256400000":0,"1558260000000":0,"1558263600000":193},"counted":[["#BREAKING",5],["#moms",6],["#EEUU",6],["#toddlers",6],["#MAGAmemes",7],["#maga",7],["#WAKEUPAMERICA",8],["#RT",13],["#trump",14],["#FAUXnews",14],["#ccot",17],["#tcot",30],["#kag",33],["#NATO",35]],"topuser":[["bettyblack176",11],["all_sabrina",11],["MaryFabulous3",11],["lpbrown7",12],["AmericanMom2",12],["ProfSchlitzo7",12],["Pasha_Enrik",12],["trilingual1946",12],["FLpalmtree1",12],["minamoradi2020",12],["BarleyFields1",12],["AJHolland01",13],["sueludad",13],["spooner_lindsay",13],["rawlings_cindy",13],["Sekusa1",13],["atypicalblonde",14],["Pissed_Woman",14],["JeffreyHardin15",14],["kathy_levy",15],["primfreak",15],["gnod111",16],["SearchingForTr9",16],["Eyerish13",16],["GymCoachMac",17]],"sentiment":[{"Tweet_ID": 1.1292963741497016e+18, "Sentiment": 0.75, "Time": "2019-05-17 10:03:31"},{"Tweet_ID": 1.129296389337432e+18, "Sentiment": 0.0, "Time": "2019-05-17 10:03:35"}]}}
2019-06-25 22:15:57,436 no email passed on arguments... exception ignored
2019-06-25 22:15:57,436 search type: 1
2019-06-25 22:15:57,440 couldnt get the tweets data... some error ocurred:
Traceback (most recent call last):
  File "./main.py", line 89, in define_action
    return get_tweets()
  File "./main.py", line 54, in get_tweets
    return get_data()
  File "./main.py", line 42, in get_data
    term_result = term_loader.load_term_file(path + search + ".csv").to_json()  # result = JSON_Object containing pair of JSON_Objects
  File "C:\Users\Alex\WebstormProjects\PropraSeite\server\DataAnalisis\term_loader.py", line 52, in load_term_file
    tweets = pd.read_csv(path, sep=";", error_bad_lines=False)
  File "C:\Program Files (x86)\Python37-32\lib\site-packages\pandas\io\parsers.py", line 702, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "C:\Program Files (x86)\Python37-32\lib\site-packages\pandas\io\parsers.py", line 429, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "C:\Program Files (x86)\Python37-32\lib\site-packages\pandas\io\parsers.py", line 895, in __init__
    self._make_engine(self.engine)
  File "C:\Program Files (x86)\Python37-32\lib\site-packages\pandas\io\parsers.py", line 1122, in _make_engine
    self._engine = CParserWrapper(self.f, **self.options)
  File "C:\Program Files (x86)\Python37-32\lib\site-packages\pandas\io\parsers.py", line 1853, in __init__
    self._reader = parsers.TextReader(src, **kwds)
  File "pandas\_libs\parsers.pyx", line 387, in pandas._libs.parsers.TextReader.__cinit__
  File "pandas\_libs\parsers.pyx", line 705, in pandas._libs.parsers.TextReader._setup_parser_source
FileNotFoundError: [Errno 2] File b'/Data/Trump.csv' does not exist: b'/Data/Trump.csv'
2019-06-25 22:16:20,236 no email passed on arguments... exception ignored
2019-06-25 22:16:20,240 search type: 1
2019-06-25 22:16:20,510 result: {"result":{"term":{"1558213200000":16896,"1558216800000":1,"1558220400000":0,"1558224000000":0,"1558227600000":1,"1558231200000":0,"1558234800000":0,"1558238400000":0,"1558242000000":0,"1558245600000":0,"1558249200000":0,"1558252800000":0,"1558256400000":0,"1558260000000":0,"1558263600000":193},"counted":[["#BREAKING",5],["#moms",6],["#EEUU",6],["#toddlers",6],["#MAGAmemes",7],["#maga",7],["#WAKEUPAMERICA",8],["#RT",13],["#trump",14],["#FAUXnews",14],["#ccot",17],["#tcot",30],["#kag",33],["#NATO",35]],"topuser":[["bettyblack176",11],["all_sabrina",11],["MaryFabulous3",11],["lpbrown7",12],["AmericanMom2",12],["ProfSchlitzo7",12],["Pasha_Enrik",12],["trilingual1946",12],["FLpalmtree1",12],["minamoradi2020",12],["BarleyFields1",12],["AJHolland01",13],["sueludad",13],["spooner_lindsay",13],["rawlings_cindy",13],["Sekusa1",13],["atypicalblonde",14],["Pissed_Woman",14],["JeffreyHardin15",14],["kathy_levy",15],["primfreak",15],["gnod111",16],["SearchingForTr9",16],["Eyerish13",16],["GymCoachMac",17]],"sentiment":[{"Tweet_ID": 1.1292963741497016e+18, "Sentiment": 0.75, "Time": "2019-05-17 10:03:31"},{"Tweet_ID": 1.129296389337432e+18, "Sentiment": 0.0, "Time": "2019-05-17 10:03:35"}]}}
2019-06-25 22:17:09,680 no email passed on arguments... exception ignored
2019-06-25 22:17:09,684 search type: 1
2019-06-25 22:17:09,947 result: {"result":{"term":{"1558213200000":16896,"1558216800000":1,"1558220400000":0,"1558224000000":0,"1558227600000":1,"1558231200000":0,"1558234800000":0,"1558238400000":0,"1558242000000":0,"1558245600000":0,"1558249200000":0,"1558252800000":0,"1558256400000":0,"1558260000000":0,"1558263600000":193},"counted":[["#BREAKING",5],["#moms",6],["#EEUU",6],["#toddlers",6],["#MAGAmemes",7],["#maga",7],["#WAKEUPAMERICA",8],["#RT",13],["#trump",14],["#FAUXnews",14],["#ccot",17],["#tcot",30],["#kag",33],["#NATO",35]],"topuser":[["bettyblack176",11],["all_sabrina",11],["MaryFabulous3",11],["lpbrown7",12],["AmericanMom2",12],["ProfSchlitzo7",12],["Pasha_Enrik",12],["trilingual1946",12],["FLpalmtree1",12],["minamoradi2020",12],["BarleyFields1",12],["AJHolland01",13],["sueludad",13],["spooner_lindsay",13],["rawlings_cindy",13],["Sekusa1",13],["atypicalblonde",14],["Pissed_Woman",14],["JeffreyHardin15",14],["kathy_levy",15],["primfreak",15],["gnod111",16],["SearchingForTr9",16],["Eyerish13",16],["GymCoachMac",17]],"sentiment":[{"Tweet_ID": 1.1292963741497016e+18, "Sentiment": 0.75, "Time": "2019-05-17 10:03:31"},{"Tweet_ID": 1.129296389337432e+18, "Sentiment": 0.0, "Time": "2019-05-17 10:03:35"}]}}
2019-06-25 22:20:29,672 no email passed on arguments... exception ignored
2019-06-25 22:20:29,675 search type: 1
2019-06-25 22:20:29,889 result: {"result":{"term":{"1558213200000":16896,"1558216800000":1,"1558220400000":0,"1558224000000":0,"1558227600000":1,"1558231200000":0,"1558234800000":0,"1558238400000":0,"1558242000000":0,"1558245600000":0,"1558249200000":0,"1558252800000":0,"1558256400000":0,"1558260000000":0,"1558263600000":193},"counted":[["#BREAKING",5],["#moms",6],["#EEUU",6],["#toddlers",6],["#MAGAmemes",7],["#maga",7],["#WAKEUPAMERICA",8],["#RT",13],["#trump",14],["#FAUXnews",14],["#ccot",17],["#tcot",30],["#kag",33],["#NATO",35]],"topuser":[["bettyblack176",11],["all_sabrina",11],["MaryFabulous3",11],["lpbrown7",12],["AmericanMom2",12],["ProfSchlitzo7",12],["Pasha_Enrik",12],["trilingual1946",12],["FLpalmtree1",12],["minamoradi2020",12],["BarleyFields1",12],["AJHolland01",13],["sueludad",13],["spooner_lindsay",13],["rawlings_cindy",13],["Sekusa1",13],["atypicalblonde",14],["Pissed_Woman",14],["JeffreyHardin15",14],["kathy_levy",15],["primfreak",15],["gnod111",16],["SearchingForTr9",16],["Eyerish13",16],["GymCoachMac",17]],"sentiment":[{"Tweet_ID": 1.1292963741497016e+18, "Sentiment": 0.75, "Time": "2019-05-17 10:03:31"},{"Tweet_ID": 1.129296389337432e+18, "Sentiment": 0.0, "Time": "2019-05-17 10:03:35"}]}}
